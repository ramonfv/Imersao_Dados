{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Script_Iniciacao_Ramon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramonfv/Imersao_Dados/blob/main/Script_Iniciacao_Ramon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njFniULBRtgh"
      },
      "source": [
        "Autor:\n",
        "Ramon Fernandes Viana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn9MPDXIoeGQ"
      },
      "source": [
        "#Implementação de um sistema BCI-SSVEP\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLb5zAw-R-RF"
      },
      "source": [
        "Este script faz parte da implementação das etapas de construção de uma BCI (Brain Computer Interface).\n",
        "\n",
        "Este trabalho contém as seguintes partes: Entrada de dados, Pré-Processamento, Estração de Características, Seleção de Características e Classificação\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93OVu7NvT9pN"
      },
      "source": [
        "A base de dados utilizada neste trabalho pode ser acessada pelo link:\n",
        "http://bci.med.tsinghua.edu.cn/download.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtFQAlWCoU2C"
      },
      "source": [
        "#Bibliotecas científicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sp\n",
        "import scipy.io as sio\n",
        "from scipy import signal\n",
        "from scipy.fft import fft\n",
        "import math \n",
        "from numpy import array\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "#Biblioteca de aprendizado de máquina\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from sklearn.cross_decomposition import CCA\n",
        "from tensorflow.keras.optimizers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OK7MpKGshxe"
      },
      "source": [
        "##Importando a base de dados e selecionando os indivíduos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wMUVcR8VpCM",
        "outputId": "8f941242-5743-4ec7-f8bb-2702a869cd40"
      },
      "source": [
        "#Biblioteca para acessar o Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "#Endereço da base de dados no Google Drive\n",
        "path_database = '/content/gdrive/MyDrive/Base de dados IC/S34.mat'\n",
        "# O sinal filtrado (CAR) para o indivíduo 34 está em:\n",
        "# /content/gdrive/MyDrive/Colab Notebooks/Iniciação/Sinais_Filtrados/CAR/filtragem_CAR.mat\n",
        "\n",
        "#Autoriza a leitura do Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# O indivíduo testado -- 34          \n",
        "mat = sio.loadmat(path_database, verify_compressed_data_integrity=False) \n",
        "data = np.array(mat['data'])\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 1500, 40, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHF3WOY786lH"
      },
      "source": [
        "# Parâmetros de entrada\n",
        "# conforme definido no artigo, o sinal coletado tem duração de 6s no entanto os 0,5s iniciais e finais são desconsiderados\n",
        "int_dados = data[:,125:1375,:,:]\n",
        "rows,cols,freqs,trials = int_dados.shape\n",
        "freqList = [0,2,4,7]\n",
        "freqReal = [8,10,12,15]\n",
        "numFreq = len(freqList)\n",
        "# Frequência de Amostragem\n",
        "Fs = 250;\n",
        "res_esp = Fs/1250;\n",
        "freq = np.arange(1250)*(res_esp);\n",
        "# vetor de tempo\n",
        "time = np.arange(1250)*1/Fs;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaCHpvnbwJJK"
      },
      "source": [
        "##Encontrando as localizações de cada frequência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyi0eyzBsGin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc5410a-b588-4afa-b716-46eaef4c286a"
      },
      "source": [
        "freq_new = np.arange(0,250,1)\n",
        "freq_new.shape\n",
        "def frequencias(freq_new,numFreq, freqReal):\n",
        "  binFreq = [0 for i in range(numFreq)]\n",
        "  for localizacao in range(numFreq):  \n",
        "    binFreq[localizacao] = np.where(freq_new == freqReal[localizacao]) \n",
        "  return binFreq  \n",
        "posicoesFreq = frequencias(freq_new,numFreq, freqReal)\n",
        "posicoesFreq = np.asarray(posicoesFreq)\n",
        "for i in range(numFreq):\n",
        "  posicoesFreq[i] = posicoesFreq[i].item() \n",
        "posicoesFreq  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 8]],\n",
              "\n",
              "       [[10]],\n",
              "\n",
              "       [[12]],\n",
              "\n",
              "       [[15]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmwcekXHtARV"
      },
      "source": [
        "##Extração de Caracterísitcas - Análise com a FFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-uGki1rgmye"
      },
      "source": [
        "# matriz H - Extração com Método da FFT\n",
        "H_FFT = np.zeros((janelas*numFreq*trials,numFreq*rows))\n",
        "H_AUX = np.zeros(numFreq)\n",
        "# número de janelas do sinal\n",
        "janelas = 5                  \n",
        "for freqs_sinal in range(numFreq):\n",
        "  for trial in range(trials):\n",
        "    for jan in range(janelas):\n",
        "      for canal in range (rows):\n",
        "        janela_inicio = jan*250\n",
        "        janela_fim = (jan+1)*250\n",
        "        janela = np.arange(janela_inicio,janela_fim)\n",
        "        FFT =  np.abs(fft(int_dados[canal,janela,freqList[freqs_sinal],trial]))\n",
        "        for indices in range(numFreq):\n",
        "          H_AUX[indices] = FFT[posicoesFreq[indices]]\n",
        "        H_FFT [trials*janelas*freqs_sinal+jan+(janelas*(trial)), canal*numFreq: ((canal+1)*numFreq)] = H_AUX\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mthzle0JnzrS"
      },
      "source": [
        "## Seleção de Atributos através do método de correlação de Pearson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxGjXTBCl94q",
        "outputId": "479f0504-2c87-4834-8472-891907780ce7"
      },
      "source": [
        "# SELECOA DE ATRIBUTOS COM PEARSON\n",
        "#*************************************************\n",
        "A = np.array(H_FFT);  #matriz de características\n",
        "uns_pos = np.ones((janelas*trials,rows))\n",
        "uns_neg = -np.ones((janelas*trials,rows))\n",
        "\n",
        "Vet_1 = np.array(np.vstack((uns_pos,uns_neg,uns_pos,uns_neg)))\n",
        "Vet_2 = np.array(np.vstack((uns_neg,uns_pos,uns_neg,uns_pos)))\n",
        "\n",
        "B = np.array(np.hstack((Vet_1,Vet_2,Vet_1,Vet_2)));\n",
        "B.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7uRnEkXn6iL"
      },
      "source": [
        "##Calculos dos eletrodos mais significativos para as frequências desejadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSSncAuql3cB"
      },
      "source": [
        "Vetor_R =  np.zeros((A.shape[1],B.shape[1]))\n",
        "\n",
        "for freq in range (B.shape[1]):\n",
        "  for ch in range (A.shape[1]):\n",
        "    print(freq,ch)\n",
        "    print(A[:,ch], B[:,freq])\n",
        "    R = np.corrcoef(A[:,ch],B[:,freq])\n",
        "    Vetor_R[ch,freq] = np.abs(R[1,0])\n",
        "\n",
        "print(Vetor_R.shape)\n",
        "indices_canais = np.argsort(Vetor_R, axis=0)[::-1]\n",
        "print(indices_canais.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QgNM3GpDYT"
      },
      "source": [
        "# Classificador Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpbSKHu_pISL"
      },
      "source": [
        "## Matriz de rótulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46LO9a4PI2Ya",
        "outputId": "d67e8f3b-fd61-4dc9-816c-70eeb0333277"
      },
      "source": [
        "np.ones((num_rotulos,num_rotulos)).shape\n",
        "Ri = -np.ones((num_rotulos,num_rotulos,num_rotulos,num_rotulos)) + 2*np.identity(num_rotulos)\n",
        "Ri.ravel()\n",
        "Ri.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 30, 30, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r24q9WDtKabu",
        "outputId": "14e73623-8282-4212-faaf-d9c439562811"
      },
      "source": [
        "Rt1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH6yz6EAw84s",
        "outputId": "132c51c3-94ae-4ca7-e7f7-f236125010c1"
      },
      "source": [
        "num_rotulos = trials*janelas\n",
        "R1 = np.ones((num_rotulos,1))\n",
        "R2 = -np.ones((num_rotulos,1))\n",
        "Rt1 = np.vstack((R1,R2,R2,R2))\n",
        "Rt2 = np.vstack((R2,R1,R2,R2))\n",
        "Rt3 = np.vstack((R2,R2,R1,R2))\n",
        "Rt4 = np.vstack((R2,R2,R2,R1))\n",
        "R = np.hstack((Rt1,Rt2,Rt3,Rt4))\n",
        "print(R.shape)\n",
        "\n",
        "uns = np.ones((len(H_FFT),1))\n",
        "# matriz atributos\n",
        "H = np.array(np.hstack((H_FFT,uns)));\n",
        "H.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 257)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVBxD9oU33a-"
      },
      "source": [
        "Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP6ep440-0hB"
      },
      "source": [
        "SVM para todos os eletrodos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VUF7liR4V9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840bc17d-c1d5-4ecc-f5b7-0bc9c8002e46"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "#Considerando as matrizes com os dados em H e a matriz de rótulos R - equivalente ao código inicial do Matlab\n",
        "#Particionar os dados usando 20% para validacao\n",
        "Ht, Hv, Rt, Rv = train_test_split(H, R, test_size = 0.20)\n",
        "#SVM - treinando\n",
        "modelo1 = svm.SVC(kernel='linear').fit(Ht, Rt[:,0])\n",
        "modelo2 = svm.SVC(kernel='linear').fit(Ht, Rt[:,1])\n",
        "modelo3 = svm.SVC(kernel='linear').fit(Ht, Rt[:,2])\n",
        "modelo4 = svm.SVC(kernel='linear').fit(Ht, Rt[:,3])\n",
        "#SVM - validando\n",
        "Y1 = modelo1.predict(Hv)\n",
        "Y2 = modelo2.predict(Hv)\n",
        "Y3 = modelo3.predict(Hv)\n",
        "Y4 = modelo4.predict(Hv)\n",
        "Y = np.vstack([Y1,Y2,Y3,Y4]).transpose()\n",
        "# Y = Y1.transpose\n",
        "index = np.argmax(Y, axis=1)\n",
        "index2 = np.argmax(Rv, axis=1)\n",
        "# print(index)\n",
        "# print(index2)\n",
        "# contando os acertos\n",
        "corretos = 0\n",
        "\n",
        "for i in range(len(Rv)):\n",
        "    #if((Y[i,:]==Rv[i,:])):\n",
        "    if(index[i] == index2[i]):\n",
        "      corretos = corretos + 1\n",
        "\n",
        "val_acc = (corretos/len(Rv))*100\n",
        "print('Acurácia da validação:', val_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia da validação: 91.66666666666666\n"
          ]
        }
      ]
    }
  ]
}